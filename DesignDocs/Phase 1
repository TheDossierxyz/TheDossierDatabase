1. The "Ironclad" Contract (JSON Schema)
You cannot just give the community a prompt; you must give them a strict JSON Schema. Modern LLMs (Gemini, OpenAI, Anthropic) all support "Structured Outputs," which forces the AI to reply in a highly specific format.
You will put a schema.json file in your repo. It explicitly defines the rules:
"doc_date" MUST be formatted as YYYY-MM-DD or null.
"type" in connections MUST be one of a predefined list (e.g., EMAIL_SENT, FLIGHT, MET_WITH). No making up new relationship types.
Every connection MUST have a "quote".

2. The "Automated Bouncer" (GitHub Actions)
You do not have the time to manually read every Pull Request (PR) to see if someone's local AI messed up the formatting. You will use GitHub Actions to act as an automated bouncer.
When a user submits a PR with a batch of JSONs, GitHub will automatically run a Python validation script (validator.py). The script will check:
Syntax: Is it valid JSON? (Rejects trailing commas, missing brackets).
Compliance: Does it perfectly match your schema.json?
Graph Logic: Do the from and to IDs in the connections block actually exist in the entities block? (This prevents "broken link" errors in Neo4j).
If the script fails, the PR gets a big red X and is blocked from merging. The contributor has to fix it before you even look at it.

3. Standard Issue Gear (The Wrapper Script)
Don't let people write their own extraction scripts. Provide a standard dossier_miner.py in your repo. The script should be designed so that all the contributor has to do is:
Clone the repo.
Put their API key (OpenAI, Anthropic, or Gemini) in their .env file.
Run python dossier_miner.py --batch 001 --model gpt-4o.
Your script will handle the prompt, the schema enforcement, and the saving. They just supply the compute power.

4. The "Hallucination Trap" (Quote Verification)
The biggest risk of someone using a cheap, weak AI model is hallucination. The AI might invent a connection between two people that doesn't exist.
Because you brilliantly built the proof_quote requirement into your Phase 2 prompt, your GitHub Action can catch this. You can add a rule to your validator: The string in proof_quote must physically exist within the raw text of the document. If the AI hallucinated the quote, the validator script will flag it as a hallucination and reject the PR.

How to structure the GitHub Repo:
/data/raw_batches/ (Zip files of 100 PDFs each. Contributors claim a batch).
/data/processed/ (Where they submit their JSONs).
/src/dossier_miner.py (The script they run).
/tests/validator.py (The script GitHub runs to check their work).